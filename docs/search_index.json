[["index.html", "Factors Contributing To Recession Chapter 1 Introduction", " Factors Contributing To Recession Jishan Desai, Sanket Bhandari, Shubham Bhalala 2022-12-15 Chapter 1 Introduction A recession is a period of economic decline, typically characterized by a decrease in the gross domestic product (GDP), a high unemployment rate, and a drop in the stock market. Various factors, including a downturn in the housing market, a decline in consumer spending, a decrease in business investment, or a drop in exports, can cause recessions. Other factors contributing to a recession include rising interest rates, political instability, and natural disasters. Recessions can significantly impact individuals, businesses, and the overall economy, and they can last for several months or even years. Governments and central banks may implement various policies to mitigate the effects of a recession and stimulate economic growth. As the world is in fear of going into recession, we are trying to predict a period of recession based on Federal Reserve Economic Data. After doing some research, we came up with six critical recession indicators: 3 months Bill rate, Capacity Utilization, Manufacturing, Industrial Production, CPI Index, 10 Years Rate, and Unemployment Rate. The project aims to examine how the change in these factors has resulted in recessions in the past and, based on that, try to find a correlation between these variables, which will, in turn, help predict the future possibility of a recession. "],["proposal.html", "Chapter 2 Proposal 2.1 Research topic 2.2 Data availability 2.3 References", " Chapter 2 Proposal Recession is said to occur when there is constant fall in GDP of a country for two consecutive quarters. While some economists say when overall “economy” is not doing well. However, there are no specific factors to laid out which are defined to identify if a country is under recession. We want to propose a solution to this problem using EDA.Specifically, we want to use EDA on data available on years in which recession occurred and analyze co-relating factors contributing to the recession. (Specific to USA).In other words, we want to perform EDA to be able pinpoint specific factors which clearly indicates that a recession in going occur. 2.1 Research topic Factors Contributing to a Recession 2.2 Data availability For finding features contributing to recession we will be using different financial datasets combined together in which the target variable will represent the period of expansion or recession. For the target variable, the value “1” will represent a period of recession and the value “0” will represent a period of expansion. This time series is an interpretation of US Business Cycle Expansions and Contractions data provided by The National Bureau of Economic Research (NBER). The dataset has a frequency of a month. For identifying the possible features, we are using 6 different time series which will form the final dataset after combining all the time series together. 3 months Bill rate: This is a 3-Months Treasury Bill Secondary Market Rate. The dataset can be retrieved from FRED, Federal Reserve Bank of St. Louis. The source of the dataset is the Board of Governors of the Federal Reserve System (US). Update frequency: Monthly. Citation: Board of Governors of the Federal Reserve System (US), 3-Month Treasury Bill Secondary Market Rate, Discount Basis [TB3MS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/TB3MS, October 30, 2022. Capacity Utilization, Manufacturing: This is a Capacity Utilization of the manufacturing sector in the USA. The capacity utilization rate for a particular industry is equal to an output index divided by a capacity index. The Federal Reserve Board’s capacity indexes attempt to capture the concept of sustainable maximum output-the greatest level of output a plant can maintain within the framework of a realistic work schedule, after factoring in normal downtime and assuming sufficient availability of inputs to operate the capital in place. The dataset can be retrieved from FRED, Federal Reserve Bank of St. Louis. The source of the dataset is the Board of Governors of the Federal Reserve System (US). Update frequency: Monthly. Citation: Board of Governors of the Federal Reserve System (US), Capacity Utilization: Manufacturing (SIC) [CUMFNS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/CUMFNS, October 30, 2022. Industrial Production: The industrial production (IP) index measures the real output of all relevant establishments located in the United States, regardless of their ownership, but not those located in U.S. territories. The dataset can be retrieved from FRED, Federal Reserve Bank of St. Louis. The source of the dataset is the Board of Governors of the Federal Reserve System (US). Update frequency: Monthly. Citation: Board of Governors of the Federal Reserve System (US), Industrial Production: Total Index [INDPRO], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/INDPRO, October 30, 2022. CPI Index: is a measure of the average change over time in the prices paid by urban consumers for a market basket of consumer goods and services. Indexes are available for the U.S. and various geographic areas. Average price data for select utility, automotive fuel, and food items are also available. The dataset can be retrieved from FRED, Federal Reserve Bank of St. Louis. The source of the dataset is the Board of Governors of the Federal Reserve System (US). Update frequency: Monthly. Citation: U.S. Bureau of Labor Statistics, Consumer Price Index for All Urban Consumers: All Items in U.S. City Average [CPIAUCNS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/CPIAUCNS, October 30, 2022. 10 Years Rate: Averages of business days. For further information regarding treasury constant maturity data, please refer to the H.15 Statistical Release notes and the Treasury Yield Curve Methodology. The dataset can be retrieved from FRED the economic database of the Federal Reserve of St. Louis. The source of the dataset is the Board of Governors of the Federal Reserve System (US). Update frequency: Monthly. Citation: Board of Governors of the Federal Reserve System (US), Market Yield on U.S. Treasury Securities at 10-Year Constant Maturity, Quoted on an Investment Basis [GS10], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/GS10, October 30, 2022. Unemployment Rate: The unemployment rate represents the number of unemployed as a percentage of the labor force. Labor force data are restricted to people 16 years of age and older, who currently reside in 1 of the 50 states or the District of Columbia, who do not reside in institutions (e.g., penal and mental facilities, homes for the aged), and who are not on active duty in the Armed Forces. The dataset can be retrieved from FRED. The source of the dataset is the U.S. Bureau of Labor Statistics. Update frequency: Monthly. Citation: U.S. Bureau of Labor Statistics, Unemployment Rate [UNRATE], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/UNRATE, December 9, 2022. Recession Indicator: This time series is an interpretation of US Business Cycle Expansions and Contractions data provided by The National Bureau of Economic Research (NBER). Our time series is composed of dummy variables that represent periods of expansion and recession. The NBER identifies months and quarters of turning points without designating a date within the period that turning points occurred. The dummy variable adopts an arbitrary convention that the turning point occurred at a specific date within the period. The arbitrary convention does not reflect any judgment on this issue by the NBER’s Business Cycle Dating Committee. A value of 1 is a recessionary period, while a value of 0 is an expansionary period. For this time series, the recession begins the first day of the period following a peak and ends on the last day of the period of the trough. Citation: Federal Reserve Bank of St. Louis, NBER based Recession Indicators for the United States from the Period following the Peak through the Trough [USREC], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/USREC, December 9, 2022. 2.3 References FRED economic data: https://fred.stlouisfed.org/series/ "],["data.html", "Chapter 3 Data 3.1 Sources 3.2 Cleaning / transformation 3.3 Missing value analysis", " Chapter 3 Data As discussed before we will be merging 7 different datasets together and 8th one being our target variable recession. The final dataset will not be of the same size as of the biggest one because each individual dataframe doesn’t have same range of dates which is the common feature between all of them based upon which we will merge the data into one. The most logical join for this problem will be to use the inner join that will keep the date column common to each one of them and accordingly append the other columns of the dataset. To do this in R programming language we will have to use the function merge which by default does inner join moreover out of many available ways we have chosen to do that using nested merge. 3.1 Sources We have used all the datasets downloaded from FRED (Federal Reserve Economic Data) with an average of monthly update on their dataset. 3 months Bill rate: https://fred.stlouisfed.org/series/TB3MS Capacity Utilization, Manufacturing: https://fred.stlouisfed.org/series/CUMFNS Industrial Production: https://fred.stlouisfed.org/series/INDPRO CPI Index: https://fred.stlouisfed.org/series/CPIAUCNS 10 Years Rate: https://fred.stlouisfed.org/series/GS10 Unemployment Rate: https://fred.stlouisfed.org/series/UNRATE Recession Indicator: https://fred.stlouisfed.org/series/USREC 3.2 Cleaning / transformation months_bill &lt;- read.csv(&#39;./TB3MS.csv&#39;) capacity_utilization &lt;- read.csv(&#39;./CUMFNS.csv&#39;) industrial_prod &lt;- read.csv(&#39;./INDPRO.csv&#39;) cpi_index &lt;- read.csv(&#39;./CPIAUCNS.csv&#39;) year_rate_10 &lt;- read.csv(&#39;./GS10.csv&#39;) unemployment_rate &lt;- read.csv(&#39;./UNRATE.csv&#39;) us_recession &lt;- read.csv(&#39;./USREC.csv&#39;) colnames(months_bill) ## [1] &quot;DATE&quot; &quot;TB3MS&quot; colnames(capacity_utilization) ## [1] &quot;DATE&quot; &quot;CUMFNS&quot; colnames(industrial_prod) ## [1] &quot;DATE&quot; &quot;INDPRO&quot; colnames(cpi_index) ## [1] &quot;DATE&quot; &quot;CPIAUCNS&quot; colnames(year_rate_10) ## [1] &quot;DATE&quot; &quot;GS10&quot; colnames(unemployment_rate) ## [1] &quot;DATE&quot; &quot;UNRATE&quot; colnames(us_recession) ## [1] &quot;DATE&quot; &quot;USREC&quot; #All have common col called DATE, and since our target variable is recession we have to get data filtered according to the available DATE in recession table. data &lt;- merge(x = year_rate_10, y = merge(x = unemployment_rate, y = merge(x = capacity_utilization, y = merge(x = months_bill, y = merge(x = industrial_prod, y = merge(x = cpi_index, y = us_recession), by = &#39;DATE&#39;), by = &#39;DATE&#39;), by = &#39;DATE&#39;), by = &#39;DATE&#39;), by = &#39;DATE&#39;) which(is.na(data)) ## integer(0) #write.csv(data, &#39;./recession_forecasting_data.csv&#39;) Each dataframe have a common value named DATE on which we will merge, to do that as explained before we will inner join the frames using merge function that does it by default, since our initial data frames doesn’t had NaN values, our resulting values is not showing signs of NaN or missing values. This can be shown in a graphical way in the following section. 3.3 Missing value analysis install.packages(&quot;remotes&quot;) ## Error in install.packages : Updating loaded packages remotes::install_github(&quot;jtr13/redav&quot;) install.packages(&quot;redav&quot;) ## Error in install.packages : Updating loaded packages library(redav) plot_missing(data, percent = FALSE) Notice that there are three parts in the plotted graph. The top part shows the number of missing values in each column. The middle part presents the missing patterns and the right part shows the counts for each missing patterns. If there had been any missing values, it would have been displayed in the middle part of the graph and the top part would have shown the number of those missing values and the right part would have shown the counts for each missing patterns. But our data set doesn’t have any missing values so the graph is empty with num of rows missing and the row count of missing values being zero. "],["results.html", "Chapter 4 Results", " Chapter 4 Results install.packages(&quot;devtools&quot;) ## Error in install.packages : Updating loaded packages library(devtools) install_github(&quot;ggobi/ggally&quot;) ## These packages have more recent versions available. ## It is recommended to update all of them. ## Which would you like to update? ## ## 1: All ## 2: CRAN packages only ## 3: None ## 4: cli (3.4.0 -&gt; 3.4.1) [CRAN] ## 5: vctrs (0.4.1 -&gt; 0.5.1) [CRAN] ## 6: rlang (1.0.5 -&gt; 1.0.6) [CRAN] ## 7: lifecycle (1.0.2 -&gt; 1.0.3) [CRAN] ## 8: cpp11 (0.4.2 -&gt; 0.4.3) [CRAN] ## 9: tidyselect (1.1.2 -&gt; 1.2.0) [CRAN] ## 10: purrr (0.3.4 -&gt; 0.3.5) [CRAN] ## 11: isoband (0.2.5 -&gt; 0.2.6) [CRAN] ## 12: bit (4.0.4 -&gt; 4.0.5) [CRAN] ## 13: vroom (1.5.7 -&gt; 1.6.0) [CRAN] ## 14: crayon (1.5.1 -&gt; 1.5.2) [CRAN] ## 15: readr (2.1.2 -&gt; 2.1.3) [CRAN] ## 16: ggplot2 (3.3.6 -&gt; 3.4.0) [CRAN] ## 17: stringr (1.4.1 -&gt; 1.5.0) [CRAN] ## 18: plyr (1.8.7 -&gt; 1.8.8) [CRAN] ## ## checking for file ‘/private/var/folders/gl/gc9370p92px37cdb3gs2xdrc0000gn/T/RtmpshbBiw/remotes8d3ed61bdd/ggobi-ggally-4d8fa81/DESCRIPTION’ ... ✔ checking for file ‘/private/var/folders/gl/gc9370p92px37cdb3gs2xdrc0000gn/T/RtmpshbBiw/remotes8d3ed61bdd/ggobi-ggally-4d8fa81/DESCRIPTION’ ## ─ preparing ‘GGally’: ## checking DESCRIPTION meta-information ... ✔ checking DESCRIPTION meta-information ## ─ installing the package to process help pages ## ─ checking for LF line-endings in source and make files and shell scripts (3.4s) ## ─ checking for empty or unneeded directories ## Removed empty directory ‘GGally/notes’ ## Removed empty directory ‘GGally/scripts’ ## ─ building ‘GGally_2.1.2.9000.tar.gz’ ## ## install.packages(&quot;GGally&quot;) ## ## The downloaded binary packages are in ## /var/folders/gl/gc9370p92px37cdb3gs2xdrc0000gn/T//RtmpshbBiw/downloaded_packages install.packages(&quot;corrplot&quot;) ## Error in install.packages : Updating loaded packages library(ggplot2) library(GGally) library(tidyr) library(tidyverse) library(scales) library(corrplot) x &lt;- factor(data$USREC) ggplot(data, aes(x)) + geom_bar()+ ggtitle(&quot;Recession/ Non Recession Frequency&quot;) + labs (x = &quot;Recession&quot;, y = &quot;Count&quot;) To get an idea about the distribution of the target variable, i.e., USREC (US Recession), we decided to plot a bar plot of the same. The graph makes it clear that the data set is unbalanced. There are more than 100 data points with USREC= 1 and around 700 with USREC= 0. This graph indicates that while training a predictive model, we’ll need to do oversampling or undersampling to make the dataset balanced for training and prediction. Recession &lt;- as.factor(data$USREC) ggpairs(data,legend = 1,columns=2:7,aes(color= Recession, alpha = 0.4), upper = list(continuous = &quot;blank&quot;, combo = &quot;box_no_facet&quot;), lower = list(continuous = wrap(&quot;points&quot;, alpha = 0.3, size=0.3), combo = wrap(&quot;dot&quot;, alpha = 0.4, size=0.3) ), title = &quot;Correlation Between factors&quot;) + theme(legend.position = &quot;right&quot;) df &lt;- data[ -c(1) ] corrplot2 &lt;- function(data, method = &quot;pearson&quot;, sig.level = 0.05, order = &quot;original&quot;, diag = FALSE, type = &quot;upper&quot;, tl.srt = 90, number.font = 1, number.cex = 1, mar = c(0, 0, 0, 0)) { data_incomplete &lt;- data data &lt;- data[complete.cases(data), ] mat &lt;- cor(data, method = method) cor.mtest &lt;- function(mat, method) { mat &lt;- as.matrix(mat) n &lt;- ncol(mat) p.mat &lt;- matrix(NA, n, n) diag(p.mat) &lt;- 0 for (i in 1:(n - 1)) { for (j in (i + 1):n) { tmp &lt;- cor.test(mat[, i], mat[, j], method = method) p.mat[i, j] &lt;- p.mat[j, i] &lt;- tmp$p.value } } colnames(p.mat) &lt;- rownames(p.mat) &lt;- colnames(mat) p.mat } p.mat &lt;- cor.mtest(data, method = method) col &lt;- colorRampPalette(c(&quot;#BB4444&quot;, &quot;#EE9988&quot;, &quot;#FFFFFF&quot;, &quot;#77AADD&quot;, &quot;#4477AA&quot;)) corrplot(mat, method = &quot;color&quot;, col = col(200), number.font = number.font, mar = mar, number.cex = number.cex, type = type, order = order, addCoef.col = &quot;black&quot;, # add correlation coefficient tl.col = &quot;black&quot;, tl.srt = tl.srt, # rotation of text labels # combine with significance level p.mat = p.mat, sig.level = sig.level, insig = &quot;blank&quot;, # hide correlation coefficients on the diagonal diag = diag ) } corrplot2( data = df, method = &quot;pearson&quot;, sig.level = 0.05, order = &quot;original&quot;, diag = FALSE, type = &quot;upper&quot;, tl.srt = 75, ) ggparcoord(data, columns = 2:8, groupColumn=8, alphaLines = .1, scale = &quot;uniminmax&quot;, mapping=aes(color=as.factor(USREC)))+ scale_color_discrete(&quot;USREC&quot;)+ ggtitle(&quot;Parallel plot of different variables&quot;) To compare multiple variables or features simultaneously, we are using parallel plots which gives a quick and intuitive comparison of the relationships between the different variables. The first observation points towards unbalnced nature of the datset that there are a lot more red lines than blue lines. USREC is the target variable hence it has only two values 0 and 1. This parallel plot shows that the features ‘UNRATE’ and ‘CUMFNS’ are negatively correlated. ‘INDPRO’ and ‘CPIAUCNS’ are positively correlated as there are parallel lines in between them. Also the correlation between other variables which are not adjacent to each other in parallel plot can be further examined using pairplot or correlation plot. recession_dates &lt;- filter(data, USREC == &quot;1&quot;) recession_years &lt;- unique(lubridate::year(as.Date(recession_dates$DATE))) data_copy &lt;- data data_copy$USREC &lt;- data_copy$USREC * 100 data_copy$DATE &lt;- lubridate::year(as.Date(data_copy$DATE)) tidy_data &lt;- data_copy %&gt;% pivot_longer(cols = -c(&quot;DATE&quot;,&quot;USREC&quot;), names_to = &quot;Factors&quot;) |&gt; mutate(Factors = forcats::fct_reorder2(Factors,DATE, value)) ggp &lt;- ggplot(tidy_data, aes(DATE, value, color = Factors)) + geom_line() + ggtitle(&quot;Factors and Recession Relation&quot;) + labs (x = &quot;&quot;, y = &quot;Value&quot;) + theme_grey(16) + theme(legend.title = element_blank()) + scale_y_continuous(limits = c(0, 100,5)) ggp + geom_vline(xintercept = recession_years, alpha = 0.2) Till now, we were able to figure out the relationships between the factors which may potentially be responsible for the recession. With the help of this time series, we will attempt to identify if there is a pattern between features and recession. To identify this, we have plotted a time series graph over a series of years and there is a vertical line on the years during which there was recession. One clear feature is CUMFNS which decreases during recession years because whenever there is a vertical line indicating a recession the CUMFNS is decreasing.This logically makes sense because CUMFNS stands capacity utilization which ideally should reduce during a recession. Second clear feature is INDPRO stands for Industrial Production. Over the years it has increased but during the recession years it has dropped (on vertical lines, it decreases). Since we cannot conclude much for the Factors GS10, UNRATE and TB3MS, we analyze them next using three different time series. recession_dates &lt;- filter(data, USREC == &quot;1&quot;) recession_years &lt;- unique(lubridate::year(as.Date(recession_dates$DATE))) ggplot(data_copy, aes(DATE, GS10)) + geom_line() + ggtitle(&quot;Year Rate from 1950 to 2022&quot;)+ geom_vline(xintercept = recession_years, alpha = 0.2) GS10 is market yield on security at 10 years. Intuitively, it should decrease during recession. This hypothesis is weakly supported by the graph as in general during recession years the GS10 goes down. However, it is not always the case from the time series. There are instances where the rate drops but it is not classified as recession, and there are few drops which are not that huge but that has happened during recession. So, overall this time-series is not much helpful for GS10 study and recession. However, we can use correlation graphs made earlier to find an indirect relation and use that instead of GS10. We talk more about this in the conclusion section. ggplot(data_copy, aes(DATE, UNRATE)) + geom_line() + ggtitle(&quot;Unemployment rate from 1950 to 2022&quot;)+geom_vline(xintercept = recession_years, alpha = 0.2) It can be deciphered that Unemployment and Recession go hand in hand because whenever there is rising unemployment there is a recession. Another important thing to notice is after a recession the drop in the unemployment rate is slow. However, during recession years there is a sudden increase. For instance, years leading to 1970 have a dropping unemployment rate and then in 1970 there is a sudden increase. This pattern repeats during every recession year(s) another notable instance is the period right before 2010. ggplot(data_copy, aes(DATE, TB3MS)) + geom_line() +geom_vline(xintercept = recession_years, alpha = 0.2) + ggtitle(&quot;Months bill from 1950 to 2022&quot;) We can see a weak relation between Monthly bills and recession. In general it appears that whenever there is a sudden drop in monthly bills value by high numbers, then there happens to be a recession. Although there are drops in years where there is no recession, the amount of drop during recession years is significant. So, if there is a significant drop over a very short time, there are chances of that time being a recession. However, this is a weak relationship because there are years where bills have increased during recession. One of the possible reasons for this discrepancy is the vertical lines are made based on x-intercepts which are discrete variables as it is year. However, the time series is actually based on dates so there are multiple points for the same year. So, if there is some pattern we cannot really identify that. For this reason, we say that this is a weak relation. "],["interactive-component.html", "Chapter 5 Interactive component 5.1 D3.js 5.2 Interactive Graph", " Chapter 5 Interactive component 5.1 D3.js D3.js (short for Data-Driven Documents) is a JavaScript library for creating dynamic, interactive data visualizations in web browsers. It uses web standards such as HTML, CSS, and SVG to create visualizations, which can be manipulated through code using the D3 library. D3 is particularly powerful for manipulating and rendering data as graphics, making it well-suited for data visualization tasks such as creating charts, plots, and maps. It can handle large datasets efficiently and can bind data to the Document Object Model (DOM), allowing for interactive visualizations that can be updated in real-time as the data changes. D3 is often used in combination with other libraries and frameworks, such as Angular, React, and Vue.js, to create interactive and complex visualizations in web applications. It is widely used by data scientists, statisticians, and developers to create rich, interactive visualizations of data. 5.2 Interactive Graph Link to VizHub visualization, here is the link to the visualization created using d3.js and hosted on VizHub. You can scroll down a bit to find two buttons named “Next Year” &amp; “Previous Year” wherein the actions are designed. On clicking Next Year if there was recession in the respective year a bar would appear in a transitive motion with a color change, hence to see this transition you have to click Next Year for 14-15 times. "],["conclusion.html", "Chapter 6 Conclusion", " Chapter 6 Conclusion Discuss: main takeaways of your exploration, limitations, future directions, lessons learned. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
