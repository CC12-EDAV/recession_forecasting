--- 
title: "Factors Contributing To Recession"
author: "Jishan Desai, Sanket Bhandari, Shubham Bhalala"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---
```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```

# Introduction


<!--chapter:end:index.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Proposal
 
 Recession is said to occur when there is constant fall in GDP of a country for two consecutive quarters. While some economists say when overall "economy" is not doing well. However, there are no specific factors to laid out which are defined to identify if a country is under recession. We want to propose a solution to this problem using EDA.Specifically, we want to use EDA on data available on years in which recession occurred and analyze co-relating factors contributing to the recession. (Specific to USA).In other words, we want to perform EDA to be able pinpoint specific factors which clearly indicates that a recession in going occur.
 
## Research topic

Factors Contributing to a Recession


## Data availability

For finding features contributing to recession we will be using different financial datasets combined together in which the target variable will represent the period of expansion or recession. For the target variable, the value “1” will represent a period of recession and the value “0” will represent a period of expansion. This time series is an interpretation of US Business Cycle Expansions and Contractions data provided by The National Bureau of Economic Research (NBER). The dataset has a frequency of a month. 

For identifying the possible features, we are using 6 different time series which will form the final dataset after combining all the time series together.

1. 3 months Bill rate: This is a 3-Months Treasury Bill Secondary Market Rate.
The dataset can be retrieved from FRED, Federal Reserve Bank of St. Louis.
The source of the dataset is the Board of Governors of the Federal Reserve System (US).

Update frequency: Monthly.

Citation: Board of Governors of the Federal Reserve System (US), 3-Month Treasury Bill Secondary Market Rate, Discount Basis [TB3MS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/TB3MS, October 30, 2022.

2. Capacity Utilization, Manufacturing: This is a Capacity Utilization of the manufacturing sector in the USA. 
The capacity utilization rate for a particular industry is equal to an output index divided by a capacity index. The Federal Reserve Board's capacity indexes attempt to capture the concept of sustainable maximum output-the greatest level of output a plant can maintain within the framework of a realistic work schedule, after factoring in normal downtime and assuming sufficient availability of inputs to operate the capital in place.
The dataset can be retrieved from  FRED, Federal Reserve Bank of St. Louis.
The source of the dataset is the Board of Governors of the Federal Reserve System (US).
Update frequency: Monthly.

Citation: Board of Governors of the Federal Reserve System (US), Capacity Utilization: Manufacturing (SIC) [CUMFNS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/CUMFNS, October 30, 2022.

3. Industrial Production: The industrial production (IP) index measures the real output of all relevant establishments located in the United States, regardless of their ownership, but not those located in U.S. territories.
The dataset can be retrieved from FRED,  Federal Reserve Bank of St. Louis.
The source of the dataset is the Board of Governors of the Federal Reserve System (US).
Update frequency: Monthly.

Citation: Board of Governors of the Federal Reserve System (US), Industrial Production: Total Index [INDPRO], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/INDPRO, October 30, 2022.

4. CPI Index: is a measure of the average change over time in the prices paid by urban consumers for a market basket of consumer goods and services. Indexes are available for the U.S. and various geographic areas. Average price data for select utility, automotive fuel, and food items are also available.

The dataset can be retrieved from FRED, Federal Reserve Bank of St. Louis.
The source of the dataset is the Board of Governors of the Federal Reserve System (US).
Update frequency: Monthly.

Citation: U.S. Bureau of Labor Statistics, Consumer Price Index for All Urban Consumers: All Items in U.S. City Average [CPIAUCNS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/CPIAUCNS, October 30, 2022.

5. 10 Years Rate: Averages of business days. For further information regarding treasury constant maturity data, please refer to the H.15 Statistical Release notes and the Treasury Yield Curve Methodology.

The dataset can be retrieved from FRED the economic database of the Federal Reserve of St. Louis.

The source of the dataset is the Board of Governors of the Federal Reserve System (US).
Update frequency: Monthly.

Citation: Board of Governors of the Federal Reserve System (US), Market Yield on U.S. Treasury Securities at 10-Year Constant Maturity, Quoted on an Investment Basis [GS10], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/GS10, October 30, 2022.


6. Unemployment Rate: The unemployment rate represents the number of unemployed as a percentage of the labor force. Labor force data are restricted to people 16 years of age and older, who currently reside in 1 of the 50 states or the District of Columbia, who do not reside in institutions (e.g., penal and mental facilities, homes for the aged), and who are not on active duty in the Armed Forces.
The dataset can be retrieved from FRED.
The source of the dataset is the U.S. Bureau of Labor Statistics.
Update frequency: Monthly.

Citation: U.S. Bureau of Labor Statistics, Unemployment Rate [UNRATE], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/UNRATE, December 9, 2022.

7. Recession Indicator: This time series is an interpretation of US Business Cycle Expansions and Contractions data provided by The National Bureau of Economic Research (NBER). Our time series is composed of dummy variables that represent periods of expansion and recession. The NBER identifies months and quarters of turning points without designating a date within the period that turning points occurred. The dummy variable adopts an arbitrary convention that the turning point occurred at a specific date within the period. The arbitrary convention does not reflect any judgment on this issue by the NBER's Business Cycle Dating Committee. A value of 1 is a recessionary period, while a value of 0 is an expansionary period. For this time series, the recession begins the first day of the period following a peak and ends on the last day of the period of the trough.

Citation: 
Federal Reserve Bank of St. Louis, NBER based Recession Indicators for the United States from the Period following the Peak through the Trough [USREC], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/USREC, December 9, 2022.

## References
1. FRED economic data: https://fred.stlouisfed.org/series/

<!--chapter:end:proposal.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Data 
As discussed before we will be merging 7 different dataset into and 8'th one being our target variable recession the final dataset will not be of the same size as of the biggest one because each individual dataframe doesn't have same range of dates which is the common feature between all of them based upon which we will merge the data into one. The most logical join for this problem will be to use the inner join that will keep the date column common to each one of then and accordingly append the other columns of the dataset. To do this in R programming language we will have to use the function merge which by default does inner join moreover out of many available ways we have chosen to do that using nested merge.

## Sources
We have used all the datasets downloaded from FRED (Federal Reserve Economic Data) with an average of monthly update on their dataset. 

1. 3 months Bill rate: https://fred.stlouisfed.org/series/TB3MS

2. Capacity Utilization, Manufacturing: https://fred.stlouisfed.org/series/CUMFNS

3. Industrial Production: https://fred.stlouisfed.org/series/INDPRO

4. CPI Index: https://fred.stlouisfed.org/series/CPIAUCNS

5. 10 Years Rate: https://fred.stlouisfed.org/series/GS10

6. Unemployment Rate: https://fred.stlouisfed.org/series/UNRATE

7. Recession Indicator: https://fred.stlouisfed.org/series/USREC

## Cleaning / transformation
```{r, echo=TRUE}
months_bill <- read.csv('./TB3MS.csv')
capacity_utilization <- read.csv('./CUMFNS.csv')
industrial_prod <- read.csv('./INDPRO.csv')
cpi_index <- read.csv('./CPIAUCNS.csv')
year_rate_10 <- read.csv('./GS10.csv')
unemployment_rate <- read.csv('./UNRATE.csv')
us_recession <- read.csv('./USREC.csv')

colnames(months_bill)
colnames(capacity_utilization)
colnames(industrial_prod)
colnames(cpi_index)
colnames(year_rate_10)
colnames(unemployment_rate)
colnames(us_recession)

#All have common col called DATE, and since our target variable is recession we have to get data filtered according to the available DATE in recession table.

data <- merge(x = year_rate_10, 
      y = merge(x = unemployment_rate, 
                y = merge(x = capacity_utilization, 
                          y = merge(x = months_bill, 
                                    y = merge(x = industrial_prod, 
                                              y = merge(x = cpi_index, 
                                                        y = us_recession), by = 'DATE'), by = 'DATE'), by = 'DATE'), by = 'DATE'), by = 'DATE')
which(is.na(data))
#write.csv(data, './recession_forecasting_data.csv')
```

Each dataframe have a common value named DATE on which we will merge, to do that as explained before we will inner join the frames using merge function that does it by default, since our initial data frames doesn't had NaN values, our resulting values is not showing signs of NaN or missing values. This can be shown in a graphical way in the following section.

## Missing value analysis
```{r, echo=TRUE}
install.packages("remotes")
remotes::install_github("jtr13/redav")
install.packages("redav")
library(redav)

plot_missing(data, percent = FALSE)
```
Notice that there are three parts in the plotted graph. 
The top part shows the number of missing values in each column. 
The middle part presents the missing patterns and the right part shows the counts for each missing patterns.
If there had been any missing values, it would have been displayed in the middle part of the graph and the top part would have shown the number of those missing values and the right part would have shown the counts for each missing patterns. But our data set doesn't have any missing values so the graph is empty with num of rows missing and the row count of missing values being zero.

<!--chapter:end:data.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Results
```{r, echo=TRUE}
install.packages("devtools")
library(devtools)
install_github("ggobi/ggally")
install.packages("GGally")
install.packages("corrplot")
library(ggplot2)
library(GGally)
library(tidyr)
library(tidyverse)
library(scales)  
library(corrplot)

```

```{r, echo=TRUE}
x <- factor(data$USREC) 
ggplot(data, aes(x)) + 
  geom_bar()+
  ggtitle("Recession/ Non Recession Frequency") +  labs (x = "Recession", y = "Count")
```

```{r, echo=TRUE}
Recession <- as.factor(data$USREC)
ggpairs(data,legend = 1,columns=2:7,aes(color= Recession, alpha = 0.4),
        upper = list(continuous = "blank", combo = "box_no_facet"),
        lower = list(continuous = wrap("points", alpha = 0.3,    size=0.3), 
                     combo = wrap("dot", alpha = 0.4,            size=0.3) ), title = "Correlation Between factors") + 
  theme(legend.position = "right")
```




```{r, echo=TRUE}
df <- data[ -c(1) ]

corrplot2 <- function(data,
                      method = "pearson",
                      sig.level = 0.05,
                      order = "original",
                      diag = FALSE,
                      type = "upper",
                      tl.srt = 90,
                      number.font = 1,
                      number.cex = 1,
                      mar = c(0, 0, 0, 0)) {
  data_incomplete <- data
  data <- data[complete.cases(data), ]
  mat <- cor(data, method = method)
  cor.mtest <- function(mat, method) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat <- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
      for (j in (i + 1):n) {
        tmp <- cor.test(mat[, i], mat[, j], method = method)
        p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
      }
    }
    colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
    p.mat
  }
  p.mat <- cor.mtest(data, method = method)
  col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
  corrplot(mat,
           method = "color", col = col(200), number.font = number.font,
           mar = mar, number.cex = number.cex,
           type = type, order = order,
           addCoef.col = "black", # add correlation coefficient
           tl.col = "black", tl.srt = tl.srt, # rotation of text labels
           # combine with significance level
           p.mat = p.mat, sig.level = sig.level, insig = "blank",
           # hide correlation coefficients on the diagonal
           diag = diag
  )
}

corrplot2(
  data = df,
  method = "pearson",
  sig.level = 0.05,
  order = "original",
  diag = FALSE,
  type = "upper",
  tl.srt = 75,
  ) 
```





```{r, echo=TRUE}
ggparcoord(data, columns = 2:8, groupColumn=8, alphaLines = .1, scale = "uniminmax", 
           mapping=aes(color=as.factor(USREC)))+
  scale_color_discrete("USREC")+
  ggtitle("Parallel plot of different variables") 
```

```{r, echo=TRUE}

```


```{r, echo=TRUE}
recession_dates <- filter(data, USREC == "1")

recession_years <- unique(lubridate::year(as.Date(recession_dates$DATE)))

data_copy <- data
data_copy$USREC <- data_copy$USREC * 100
data_copy$DATE <- lubridate::year(as.Date(data_copy$DATE))

tidy_data <- data_copy %>% pivot_longer(cols = -c("DATE","USREC"), names_to = "Factors") |> mutate(Factors = forcats::fct_reorder2(Factors,DATE, value))

ggp <- ggplot(tidy_data, aes(DATE, value, color = Factors)) +
  geom_line() +
  ggtitle("Factors and Recession Relation") +  labs (x = "", y = "Value") +
  theme_grey(16) +
  theme(legend.title = element_blank()) + scale_y_continuous(limits = c(0, 100,5)) 
ggp +  geom_vline(xintercept = recession_years, alpha = 0.2) 
```
```{r, echo=TRUE}
recession_dates <- filter(data, USREC == "1")

recession_years <- unique(lubridate::year(as.Date(recession_dates$DATE)))

ggplot(data_copy, 
       aes(DATE, GS10)) + 
  geom_line() +
  ggtitle("Year Rate from 1950 to 2022")+  geom_vline(xintercept = recession_years, alpha = 0.2) 


```

```{r, echo=TRUE}
ggplot(data_copy, 
       aes(DATE, UNRATE)) + 
  geom_line() +
  ggtitle("Unemployment rate from 1950 to 2022")+geom_vline(xintercept = recession_years, alpha = 0.2) 



```

```{r, echo=TRUE}
ggplot(data_copy, 
       aes(DATE, TB3MS)) + 
  geom_line() +geom_vline(xintercept = recession_years, alpha = 0.2) +
  ggtitle("Months bill from 1950 to 2022")
```

```{r, echo=TRUE}

```





<!--chapter:end:results.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Interactive component



<!--chapter:end:interactive.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Conclusion


<!--chapter:end:conclusion.Rmd-->

